{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87059708-e62a-4339-874b-89e96b206091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "            SparkSession\n",
    "                .builder\n",
    "                .appName(\"SparkPartitionsApp\")\n",
    "    \n",
    "                # Local\n",
    "                .master(\"local[4]\")\n",
    "    \n",
    "                # Standalone/YARN    \n",
    "    \n",
    "                #.config(\"spark.cores.max\",            \"6\")\n",
    "    \n",
    "                #.config(\"spark.executor.memory\",      \"2g\")\n",
    "                #.config(\"spark.executor.cores\",       \"2\")\n",
    "    \n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "                .config(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "    \n",
    "                .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4113c77-535c-4cbb-a594-fd673b03bde7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check default parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f8d251-1f2d-4af6-925a-70bf32d663a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: 8"
     ]
    }
   ],
   "source": [
    "sc.defaultParallelism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7b9645b-b37a-4b47-a112-0799ea59ed1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Partition settings while reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb807def-6df9-45a4-8d6f-e064f40bdb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check partitions for a small dataset\n",
    "\n",
    "Spark finds optimal number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2129a7-5fa3-4e2e-b65a-6f1341662077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions = 1\nRecord Count = 265\n"
     ]
    }
   ],
   "source": [
    "# Read Taxi Zones data\n",
    "taxiZonesDF = (\n",
    "                  spark\n",
    "                    .read                    \n",
    "                    .option(\"inferSchema\", \"true\")\n",
    "                    .csv(\"/FileStore/tables/TaxiZones.csv\")\n",
    "              )\n",
    "\n",
    "# Check number of partitions\n",
    "print(\"Partitions = \"    + str( taxiZonesDF.rdd.getNumPartitions() ))\n",
    "\n",
    "# Check number of records\n",
    "print(\"Record Count = \"  + str( taxiZonesDF.count() ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8012ede-4ded-4849-b254-0e397ae015d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check partitions for a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edde137b-5d12-4091-b5d1-f24e9941600d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions = 8\nRecord Count = 3675412\n"
     ]
    }
   ],
   "source": [
    "# Read Yellow Taxis data\n",
    "yellowTaxiDF = (\n",
    "                  spark\n",
    "                    .read\n",
    "                    .option(\"header\", \"true\")    \n",
    "                    .option(\"inferSchema\", \"true\")    \n",
    "                    .csv(\"/FileStore/tables/YellowTaxis_202210.csv\")\n",
    "               )\n",
    "\n",
    "# Check number of partitions\n",
    "print(\"Partitions = \"    + str( yellowTaxiDF.rdd.getNumPartitions() ))\n",
    "\n",
    "# Check number of records\n",
    "print(\"Record Count = \"  + str( yellowTaxiDF.count() ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59854c6c-7990-459a-b015-e5a25a2f2ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Change maximum partition size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f672825-090a-4b86-a382-93e92c84d499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set( \"spark.sql.files.maxPartitionBytes\", \"64m\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b92d4263-a7a6-4e00-8748-3ae089c25bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check partitions for a large dataset\n",
    "\n",
    "With smaller max partition size (64 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02d4585-cbcf-4c84-9c86-8a7233f3391b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Parallelism = 8\nPartitions = 8\n"
     ]
    }
   ],
   "source": [
    "# Read Yellow Taxis data\n",
    "yellowTaxiDF = (\n",
    "                  spark\n",
    "                    .read\n",
    "                    .option(\"header\", \"true\")    \n",
    "                    .option(\"inferSchema\", \"true\")    \n",
    "                    .csv(\"/FileStore/tables/YellowTaxis_202210.csv\")\n",
    "               )\n",
    "\n",
    "# Check default parallelism\n",
    "print(\"Default Parallelism = \"  + str( sc.defaultParallelism ))\n",
    "\n",
    "# Check number of partitions\n",
    "print(\"Partitions = \"           + str( yellowTaxiDF.rdd.getNumPartitions() ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a15d14-bb9e-4055-be77-356c2f1e73ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create method to calculate DataFrame statistics\n",
    "\n",
    "Finds data for each partition <br/>\n",
    "Calculate count of records, and min & max values of a column across each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3966e615-a708-477f-80e0-d9ece3a54e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getDataFrameStats(dataFrame, columnName):\n",
    "\n",
    "    outputDF = (\n",
    "                    dataFrame\n",
    "\n",
    "                        # Get partition number for each record\n",
    "                        .withColumn(\"Partition Number\", spark_partition_id())\n",
    "        \n",
    "        \n",
    "                        # Group by partition, and calculate stats for a column\n",
    "                        .groupBy(\"Partition Number\")\n",
    "                        .agg(\n",
    "                                  count(\"*\").alias(\"Record Count\"),\n",
    "                                  min(columnName).alias(\"Min Column Value\"),\n",
    "                                  max(columnName).alias(\"Max Column Value\")\n",
    "                            )\n",
    "\n",
    "                        .orderBy(\"Partition Number\")\n",
    "               )\n",
    "\n",
    "    return outputDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0b9fc86-06a1-4eb9-8985-3f9046b5ce58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check stats for Yellow Taxis DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30269e79-1003-4536-9531-8923c4717704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      462318|               1|             265|\n|               1|      462170|               1|             265|\n|               2|      461742|               1|             265|\n|               3|      462063|               1|             265|\n|               4|      461831|               1|             265|\n|               5|      462118|               1|             265|\n|               6|      461884|               1|             265|\n|               7|      441286|               1|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "getDataFrameStats( yellowTaxiDF, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b49326db-2cc9-4aff-a3dd-3a49eeff59fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Partition settings while shuffling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d5d36a4-dac6-4d12-a3ac-95e76e8c00b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check default number of shuffle partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d527f5-55df-4af1-b39d-23e020af0295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: '200'"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.conf.get( \"spark.sql.shuffle.partitions\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b459898-ad0f-461a-9fc2-3929c5efc3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Apply a shuffle operation and check DataFrame stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7437cd1-1793-4d34-a0e2-195c8ea66ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions = 200\n+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|           1|             148|             148|\n|               1|           1|             243|             243|\n|               2|           1|              31|              31|\n|               3|           3|              85|             251|\n|               4|           1|              65|              65|\n|               5|           2|              53|             255|\n|               6|           1|             133|             133|\n|               7|           1|              78|              78|\n|              10|           2|             108|             155|\n|              11|           3|              34|             211|\n|              12|           3|             101|             126|\n|              13|           1|              81|              81|\n|              14|           3|              28|             210|\n|              18|           1|              76|              76|\n|              19|           2|              26|              27|\n|              21|           3|              44|             192|\n|              22|           1|             253|             253|\n|              23|           1|             236|             236|\n|              24|           1|              12|              12|\n|              25|           1|             223|             223|\n+----------------+------------+----------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data\n",
    "yellowTaxiGroupedDF = (\n",
    "                            yellowTaxiDF\n",
    "                                .groupBy(\"PULocationID\")\n",
    "                                .agg(sum(\"total_amount\"))\n",
    "                      )\n",
    "\n",
    "# Check number of partitions\n",
    "print(\"Partitions = \"  + str( yellowTaxiGroupedDF.rdd.getNumPartitions() ))\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( yellowTaxiGroupedDF, \"PULocationID\" ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4093702d-e104-4da0-9d15-ac9d35e72a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Change default number of shuffle partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41668f4b-f1bd-445a-85c2-2f4e360bca74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set( \"spark.sql.shuffle.partitions\", 3 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c28076c1-b3b3-4483-a43b-72678cc105db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Apply a shuffle operation and check DataFrame stats\n",
    "\n",
    "After changing default shuffle partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96549a68-29e3-4c85-8f25-716d717d3289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions = 3\n+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|          88|               3|             263|\n|               1|          85|               1|             265|\n|               2|          87|              11|             264|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data\n",
    "yellowTaxiGroupedDF = (\n",
    "                            yellowTaxiDF\n",
    "                                .groupBy(\"PULocationID\")\n",
    "                                .agg(sum(\"total_amount\"))\n",
    "                      )\n",
    "\n",
    "# Check number of partitions\n",
    "print(\"Partitions = \"  + str( yellowTaxiGroupedDF.rdd.getNumPartitions() ))\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( yellowTaxiGroupedDF, \"PULocationID\" ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "399939fd-5e94-4021-9fa9-1010ab9642f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea149b28-8914-452f-8fe1-85165f6e6073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check stats for Yellow Taxis DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea98b98-b7f8-4f0a-bbb3-b7435b012e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      462318|               1|             265|\n|               1|      462170|               1|             265|\n|               2|      461742|               1|             265|\n|               3|      462063|               1|             265|\n|               4|      461831|               1|             265|\n|               5|      462118|               1|             265|\n|               6|      461884|               1|             265|\n|               7|      441286|               1|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "getDataFrameStats( yellowTaxiDF, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d749203c-1a73-49a8-b0c0-136c57f42fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Repartition DataFrame: Round-Robin partitioning\n",
    "\n",
    "Create equal-sized partitions. Data is not co-located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c37bf0-a69d-4b50-8d70-79b6e5af6762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      262530|               1|             265|\n|               1|      262528|               1|             265|\n|               2|      262530|               1|             265|\n|               3|      262530|               1|             265|\n|               4|      262530|               1|             265|\n|               5|      262530|               1|             265|\n|               6|      262531|               1|             265|\n|               7|      262529|               1|             265|\n|               8|      262527|               1|             265|\n|               9|      262529|               1|             265|\n|              10|      262529|               1|             265|\n|              11|      262530|               1|             265|\n|              12|      262530|               1|             265|\n|              13|      262529|               1|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "repartionedDF1 = yellowTaxiDF.repartition( 14 )\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( repartionedDF1, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a9cce73-de6f-438d-b3a1-f5bf53931850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Repartition DataFrame: Hash partitioning\n",
    "\n",
    "Co-locates the data. Partition sizes may not be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4e160e-e346-4ab7-8b17-5eb155423fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|     1246579|               3|             263|\n|               1|     1426282|               1|             265|\n|               2|     1002551|              11|             264|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# spark.sql.shuffle.partitions = 3\n",
    "\n",
    "\n",
    "repartionedDF1 = yellowTaxiDF.repartition( \"PULocationID\" )\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( repartionedDF1, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d38978f-a48b-46d2-aa9a-6a8161c6aa4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Repartition DataFrame: Hash partitioning & define number of partitions\n",
    "\n",
    "Co-locates the data. Partition sizes may not be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48b16b00-6733-4b76-9cc1-b8a6ee6942fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      405748|              12|             261|\n|               1|      493312|               8|             250|\n|               2|      168505|              18|             263|\n|               3|      207849|               9|             260|\n|               4|      191119|              52|             257|\n|               5|      202251|              43|             258|\n|               6|      259735|              13|             265|\n|               7|      386736|              24|             255|\n|               8|      142987|               4|             254|\n|               9|      406158|               1|             251|\n|              10|      108394|              28|             234|\n|              11|      231246|               3|             241|\n|              12|      203911|               5|             259|\n|              13|      267461|              11|             240|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "repartionedDF1 = yellowTaxiDF.repartition( 14, \"PULocationID\" )\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( repartionedDF1, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c1d924a-a0e8-4344-8fe2-3c8122d59993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Repartition DataFrame: Range partitioning\n",
    "\n",
    "Sort and co-locates the data. Partition sizes may not be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f96ba33-298b-4f9e-984b-8b256a265cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      266634|               1|              50|\n|               1|      238923|              51|              79|\n|               2|      290834|              80|             113|\n|               3|      258270|             114|             132|\n|               4|      310690|             133|             141|\n|               5|      169288|             142|             143|\n|               6|      286326|             144|             161|\n|               7|      304033|             162|             164|\n|               8|      243993|             165|             186|\n|               9|      297337|             187|             231|\n|              10|      306294|             232|             236|\n|              11|      176660|             237|             237|\n|              12|      240733|             238|             246|\n|              13|      285397|             247|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "repartionedDF1 = yellowTaxiDF.repartitionByRange( 14, \"PULocationID\" )\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( repartionedDF1, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77677a95-c3db-41be-ae4f-06943e7729a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Coalesce DataFrame\n",
    "\n",
    "Reduces number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b04b647-0a38-4301-be2d-25214f7f1add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|     1848293|               1|             265|\n|               1|     1827119|               1|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coalescedDF = yellowTaxiDF.coalesce( 2 )\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( coalescedDF, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "204a47f9-e9e9-4a9e-bc06-ecbd13c3b3e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+----------------+----------------+\n|Partition Number|Record Count|Min Column Value|Max Column Value|\n+----------------+------------+----------------+----------------+\n|               0|      462318|               1|             265|\n|               1|      462170|               1|             265|\n|               2|      461742|               1|             265|\n|               3|      462063|               1|             265|\n|               4|      461831|               1|             265|\n|               5|      462118|               1|             265|\n|               6|      461884|               1|             265|\n|               7|      441286|               1|             265|\n+----------------+------------+----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coalescedDF=coalescedDF.coalesce( 14)\n",
    "\n",
    "\n",
    "# Get DataFrame stats\n",
    "getDataFrameStats( coalescedDF, \"PULocationID\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d480439-312f-4d3b-a69a-f51fa8494297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86e21d58-10f1-4e09-84c9-45b568d3abc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e2eb896-b6cf-424d-8a63-fa1e4b44df5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b4ecf07-228e-4a8b-91dc-85f5a4ed2d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69f4687d-b5a7-44e6-a9cf-b3a34244ab2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.1 - Spark Partitions",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
